{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "655cae09",
   "metadata": {},
   "source": [
    "# Machine learning model for user behavior analysis\n",
    "\n",
    "## Project information\n",
    "\n",
    "We're back at Megaline. They have launched two new plans, but many of the users are still sticking with the old ones. Megaline thinks that users might want to subscribe to the new plans if they were given a personalized recommendation.\n",
    "\n",
    "Our goal is to create a machine-learning model that can analyze user behavior and recommend a package tailored to their needs.\n",
    "\n",
    "**Objectives:**\n",
    "1. Create an ML model for this task.\n",
    "<br>\n",
    "To ensure that Megaline gets a model that does its job as intended with maximum performance, we need to do the following steps:\n",
    "1. Adjusting model hyperparameters, comparing the results, and picking the best settings,\n",
    "1. Testing the model,\n",
    "1. Conducting a sanity check on the model.\n",
    "\n",
    "## Dataset description\n",
    "\n",
    "Luckily, we can use the data that we processed in our previous project. This eliminates the need to preprocess the data, except for the ML-related standardization.\n",
    "\n",
    "`users_behavior.csv` contains the following columns:\n",
    "- `calls`: number of calls made\n",
    "- `minutes`: total duration of all calls, in minutes\n",
    "- `messages`: number of SMS messages sent\n",
    "- `mb_used`: Internet usage, in megabytes\n",
    "- `is_ultra`: plan subscribed by the user (`1`: Ultra, `0`: Smart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15509eeb",
   "metadata": {},
   "source": [
    "## Loading libraries\n",
    "\n",
    "For this project, we'll compare the performance of different classification models (as opposed to regression models) because we need to classify users into 2 plans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9b65f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataframe manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# ML model libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# sklearn tools\n",
    "from sklearn.preprocessing import StandardScaler # to standardize data, increases models' learning performance\n",
    "from sklearn.model_selection import train_test_split # to split datasets into training and testing tests\n",
    "from sklearn.metrics import accuracy_score # to calculate the model's accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b14f11",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9e7727",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>122.0</td>\n",
       "      <td>910.98</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35124.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>25.0</td>\n",
       "      <td>190.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3275.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>97.0</td>\n",
       "      <td>634.44</td>\n",
       "      <td>70.0</td>\n",
       "      <td>13974.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>64.0</td>\n",
       "      <td>462.32</td>\n",
       "      <td>90.0</td>\n",
       "      <td>31239.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>80.0</td>\n",
       "      <td>566.09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29480.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3214 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used  is_ultra\n",
       "0      40.0   311.90      83.0  19915.42         0\n",
       "1      85.0   516.75      56.0  22696.96         0\n",
       "2      77.0   467.66      86.0  21060.45         0\n",
       "3     106.0   745.53      81.0   8437.39         1\n",
       "4      66.0   418.74       1.0  14502.75         0\n",
       "...     ...      ...       ...       ...       ...\n",
       "3209  122.0   910.98      20.0  35124.90         1\n",
       "3210   25.0   190.36       0.0   3275.61         0\n",
       "3211   97.0   634.44      70.0  13974.06         0\n",
       "3212   64.0   462.32      90.0  31239.78         0\n",
       "3213   80.0   566.09       6.0  29480.52         1\n",
       "\n",
       "[3214 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'datasets\\users_behavior.csv')\n",
    "\n",
    "# Checking the dataset\n",
    "print(df.info())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50034e97",
   "metadata": {},
   "source": [
    "Although the binary values in `is_ultra` represent boolean True/False, we will keep the data type as `int64` because a logistic regression model classification results in such values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d95607d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2229\n",
       "1     985\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking target proportions\n",
    "df['is_ultra'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962f1dd0",
   "metadata": {},
   "source": [
    "Apparently, we're provided with an imbalanced dataset: Smart plan users (`is_ultra = 0`) account for ~69% of the data. To ensure that our models are not making correct predictions simply by chance, we need to set our baseline metric to a higher value. We'll set the baseline metric score to **75%**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e12501e",
   "metadata": {},
   "source": [
    "### Splitting\n",
    "\n",
    "Creating an ML model involves three steps: training, validation, and testing. We only have one dataset for all three steps, so we need to split it for use in each stage.\n",
    "\n",
    "Training requires more data than the latter two stages. Dividing the dataset with a 3:1:1 ratio (60% for training, 20% each for validation and testing) should be able to provide sufficient data for every part. Because `train_test_split` can only split a dataset into two, we'll need to execute this function twice.\n",
    "\n",
    "We will set the `random_state` hyperparameter to an arbitrary value of `12345` throughout the project. This will ensure that we get consistent results every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "747c5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into test_df (60%) and the rest (20% + 20%)\n",
    "train_df, df2 = train_test_split(df, train_size=0.6, random_state=12345)\n",
    "\n",
    "# Splitting df2 into validation and test sets\n",
    "val_df, test_df = train_test_split(df2, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b3c2ff8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1928 entries, 3027 to 482\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     1928 non-null   float64\n",
      " 1   minutes   1928 non-null   float64\n",
      " 2   messages  1928 non-null   float64\n",
      " 3   mb_used   1928 non-null   float64\n",
      " 4   is_ultra  1928 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 90.4 KB\n",
      "None\n",
      "\n",
      "val_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 643 entries, 1386 to 3197\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     643 non-null    float64\n",
      " 1   minutes   643 non-null    float64\n",
      " 2   messages  643 non-null    float64\n",
      " 3   mb_used   643 non-null    float64\n",
      " 4   is_ultra  643 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 30.1 KB\n",
      "None\n",
      "\n",
      "test_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 643 entries, 160 to 2313\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     643 non-null    float64\n",
      " 1   minutes   643 non-null    float64\n",
      " 2   messages  643 non-null    float64\n",
      " 3   mb_used   643 non-null    float64\n",
      " 4   is_ultra  643 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 30.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Checking each set\n",
    "print('train_df:')\n",
    "print(train_df.info())\n",
    "print()\n",
    "\n",
    "print('val_df:')\n",
    "print(val_df.info())\n",
    "print()\n",
    "\n",
    "print('test_df:')\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48961b2e",
   "metadata": {},
   "source": [
    "### Defining targets and features\n",
    "\n",
    "In accordance with project goals, `is_ultra` will be the target for our model and other columns will be the features. Target and features need to be separated from each of the three sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a885503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df\n",
    "train_features = train_df.drop('is_ultra', axis=1) # Excluding is_ultra from the set\n",
    "train_target = train_df['is_ultra']\n",
    "\n",
    "# val_df\n",
    "val_features = val_df.drop('is_ultra', axis=1)\n",
    "val_target = val_df['is_ultra']\n",
    "\n",
    "# test_df\n",
    "test_features = test_df.drop('is_ultra', axis=1)\n",
    "test_target = test_df['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a060109",
   "metadata": {},
   "source": [
    "### Scaling: standardization\n",
    "\n",
    "The performance of regression models is affected by the difference in data values, especially when features are measured in different units. Simply put, regression models may see data with larger numbers as having more significance than those with smaller values. Scaling increases the efficiency of regression models by converting data values into a uniform scale. To anticipate outliers in the current and future data, we will use standardization, a commonly used scaling method that is more robust to outliers.\n",
    "\n",
    "It should be noted that, due to the difference in algorithms, scaling does not have any effect on tree-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b7df0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of StandardScaler\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Fitting & transforming training data\n",
    "train_features = standard_scaler.fit_transform(X=train_features.values) # .values attribute excludes dataframe headers and prevent errors/warnings\n",
    "\n",
    "# Transforming validation & test sets\n",
    "val_features = standard_scaler.transform(X=val_features.values)\n",
    "test_features = standard_scaler.transform(X=test_features.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9390ba3e",
   "metadata": {},
   "source": [
    "## Model training & validation\n",
    "\n",
    "Next, we will train each of the three classification models and evaluate their performance in predicting the validation set. The models' performance will be measured by their validation metric scores (not training scores because they will only rise with more training). \n",
    "\n",
    "We need the model to correctly predict two classes with minimal error, so the metric in question will be accuracy. Accuracy measures how many times the model was correct at giving the correct plan recommendation.\n",
    "\n",
    "We will only take models with a **minimum of 75% accuracy**, in accordance with the baseline score mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c47ae74",
   "metadata": {},
   "source": [
    "### Decision tree\n",
    "\n",
    "The performance of this model varies by tree depth. This means that we have to keep the tree deep enough to produce the best results, but not excessively deep to prevent overfitting and wasting resources. To achieve this, we'll train and validate the model 10 times with increasing depth and pick the one with the best scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4d84800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth: 3 training accuracy: 0.8075726141078838 validation accuracy: 0.7838258164852255\n"
     ]
    }
   ],
   "source": [
    "# Defining variables to store scores and models in\n",
    "tree_train_best_score = 0\n",
    "tree_best_score = 0\n",
    "tree_best_depth = 0\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    # Creating & training models with different depths\n",
    "    tree_model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    tree_model.fit(train_features, train_target)\n",
    "    \n",
    "    # Getting training scores\n",
    "    train_pred = tree_model.predict(train_features)\n",
    "    tree_train_score = accuracy_score(train_target, train_pred)\n",
    "    \n",
    "    # Validation and obtaining validation metric scores\n",
    "    valid_pred = tree_model.predict(val_features)\n",
    "    val_acc_score = accuracy_score(val_target, valid_pred)\n",
    "    \n",
    "    # Storing the best depth and scores\n",
    "    if val_acc_score > tree_best_score:\n",
    "        tree_train_best_score = tree_train_score\n",
    "        tree_best_score = val_acc_score\n",
    "        tree_best_depth = depth\n",
    "    \n",
    "print('Best depth:', tree_best_depth, 'training accuracy:', tree_train_best_score, 'validation accuracy:', tree_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdce516d",
   "metadata": {},
   "source": [
    "The model hit peak validation accuracy at `depth = 3`, whose score (**~78.5%**) is only ~2.5% lower than the training accuracy. This score satisfies our baseline requirement. We will use this depth as the hyperparameter for our decision tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015ccac4",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "\n",
    "Next, we'll use the power of more trees (technically, estimators) at once. Being composed of several decision trees, the model's accuracy will vary based on its `max_depth` and the number of its trees (`n_estimators`). `max_depth` will be set from 1--10 and `n_estimators` will range from 10--100 with an increment of 10 estimators in every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d21c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training accuracy: 0.875\n",
      "Best validation accuracy: 0.807153965785381\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=8, n_estimators=40, random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=8, n_estimators=40, random_state=12345)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=8, n_estimators=40, random_state=12345)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining variables to store scores and models in\n",
    "forest_best_training_score = 0\n",
    "forest_best_score = 0\n",
    "forest_best_model = None\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    for estimator in range(10, 101, 10): # Setting the range of estimators with an increase of 10 estimators per iteration\n",
    "        \n",
    "        # Creating & training the model with different max_depth and n_estimators\n",
    "        forest_model = RandomForestClassifier(random_state=12345, max_depth=depth, n_estimators=estimator)\n",
    "        forest_model.fit(train_features, train_target)\n",
    "        \n",
    "        # Getting training scores\n",
    "        train_pred = forest_model.predict(train_features)\n",
    "        forest_train_score = accuracy_score(train_target, train_pred)\n",
    "        \n",
    "        # Validating the model\n",
    "        val_pred = forest_model.predict(val_features)\n",
    "        val_acc_score = accuracy_score(val_target, val_pred)\n",
    "        \n",
    "        # Storing the best score and model\n",
    "        if val_acc_score > forest_best_score:\n",
    "            forest_best_training_score = forest_train_score\n",
    "            forest_best_score = val_acc_score\n",
    "            forest_best_model = forest_model\n",
    "                 \n",
    "print('Best training accuracy:', forest_best_training_score)\n",
    "print('Best validation accuracy:', forest_best_score)\n",
    "forest_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd03c84",
   "metadata": {},
   "source": [
    "Our forest model with 40 estimators at `max_depth=8` achieved the best validation accuracy of **~80.8%**, which fulfills our baseline score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6746bc65",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "Another way to classify data is to use the logistic regression model. This model is different from the previous two in that it doesn't have a `max_depth` parameter and is affected by scaling done previously. \n",
    "\n",
    "We will compare all five solvers provided by scikit-learn. `sag` and `saga` solvers need a plenty of iterations to fit well, so we will increase the `max_iter` hyperparameter to `3500` for these and use the default value of `100` for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f3ceb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liblinear training accuracy: 0.7531120331950207\n",
      "liblinear validation accuracy: 0.7558320373250389\n",
      "\n",
      "newton-cg training accuracy: 0.7531120331950207\n",
      "newton-cg validation accuracy: 0.7558320373250389\n",
      "\n",
      "lbfgs training accuracy: 0.7531120331950207\n",
      "lbfgs validation accuracy: 0.7558320373250389\n",
      "\n",
      "sag training accuracy: 0.7531120331950207\n",
      "sag validation accuracy: 0.7558320373250389\n",
      "\n",
      "saga training accuracy: 0.7531120331950207\n",
      "saga validation accuracy: 0.7558320373250389\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "\n",
    "for solver in solver_list:\n",
    "    # Creating & training logistic regression models, changing max_iter as needed\n",
    "    if solver == 'sag' or solver == 'saga':\n",
    "        logreg_model = LogisticRegression(random_state=12345, solver=solver, max_iter=3500)\n",
    "    else:\n",
    "        logreg_model = LogisticRegression(random_state=12345, solver=solver)\n",
    "    logreg_model.fit(train_features, train_target)\n",
    "    \n",
    "    # Getting training accuracy scores\n",
    "    train_pred = logreg_model.predict(train_features)\n",
    "    train_acc_score = accuracy_score(train_target, train_pred)\n",
    "    print(solver, 'training accuracy:', train_acc_score)\n",
    "\n",
    "    # Validating model & getting accuracy\n",
    "    val_pred = logreg_model.predict(val_features)\n",
    "    val_acc_score = accuracy_score(val_target, val_pred)\n",
    "    print(solver, 'validation accuracy:', val_acc_score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba5df67",
   "metadata": {},
   "source": [
    "Apparently, all of the solvers in our logistic regression model returned the same score of **~75.5%**. However, its validation accuracy is higher than its training score, indicating that it's underfitted. This might change if we had a bigger dataset to train and validate with, but for now, the logistic regression models don't seem to be the best choice for this job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f66f7bc",
   "metadata": {},
   "source": [
    "### Model training and validation results\n",
    "\n",
    "We have trained and validated three models with varying accuracy. Keeping the importance of the model making the correct recommendations, we will use the best-performing model of the three: the **random forest classifier** with `max_depth = 8, n_estimators = 40, random_state=12345`, resulting in a validation accuracy of **~80%**, which is 5% above our baseline score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5368d82c",
   "metadata": {},
   "source": [
    "## Quality check with test set & sanity check\n",
    "\n",
    "We need to verify the quality of the model using our last set, the test set. If the model can maintain its accuracy to be higher than our 75% baseline score, we can proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fa63f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7962674961119751\n"
     ]
    }
   ],
   "source": [
    "# Redefining the random forest model\n",
    "forest_final = forest_best_model\n",
    "\n",
    "# Making predictions on the test set\n",
    "test_pred = forest_final.predict(test_features)\n",
    "\n",
    "# Getting the test score\n",
    "test_acc = accuracy_score(test_target, test_pred)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770de3d1",
   "metadata": {},
   "source": [
    "Our random forest succeeded in keeping its score only with a ~1.2% decrease from the validation accuracy.\n",
    "\n",
    "As mentioned above, the dataset is imbalanced. We have set our baseline score to 75% to ensure that the model didn't learn to classify more towards `is_ultra = 0` and that it didn't get a high accuracy score by chance. By scoring ~79.6% on the last test, we can say that our random forest model has passed the sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303f349c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We were given a dataset containing 3214 rows of users' plan usage data and their plans of choice. We noted several things about the dataset:\n",
    "- `is_ultra = 0` (~69%) dominated the target variable, making the dataset imbalanced.\n",
    "- the data are measured in different units and numerical range.\n",
    "\n",
    "The data were split into 3 parts: training (60%), validation, and test sets (20% each). Regarding the numerical values, to make the data more suitable for processing by logistic regression models, we scaled the data using sklearn's Standard Scaler. However, the performance of tree-based models were not affected by this change.\n",
    "\n",
    "The goal was to create a machine-learning model that can classify users into the best of the two plan options, so we created 3 classification ML models with varying, manually-tuned hyperparameters and compared their training & validation performance. The performance was measured with the accuracy metric because we needed to know how likely would the model provide the correct predictions. In line with the dataset's imbalance, we set our **baseline accuracy score to 75%** to ensure that the model weren't simply making random correct guesses.\n",
    "\n",
    "The three models, their best hyperparameters, and their respective scores were:\n",
    "1. Decision tree classifier (`max_depth = 3, random_state = 12345`) <br>\n",
    "Accuracy: **~78.5%** </br>\n",
    "1. Random forest classifier (`max_depth = 8, n_estimators = 40, random_state = 12345`)<br>\n",
    "Accuracy: **~80.8%** </br>\n",
    "1. Logistic regression classifier (any solver, `random_state = 12345`)<br>\n",
    "Accuracy: **~75.5%** </br>\n",
    "\n",
    "Our random forest classifier yielded the best results and passed the testing stage with an accuracy of **~79.6%** which also made it pass the sanity check.\n",
    "\n",
    "To conclude, the best machine-learning model for this task would be a **random forest classifier** with the following hyperparameters: `max_depth = 8, n_estimators = 40, random_state = 12345`, fitted with our training dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
