{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f690b3e",
   "metadata": {},
   "source": [
    "# Customer churn rate predictor model\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "1. [Project information](#1)\n",
    "    1. [Dataset description](#1.1)\n",
    "    1. [Notes](#1.2)\n",
    "1. [Loading libraries](#2)\n",
    "1. [Loading dataset](#3)\n",
    "1. [Data preprocessing](#4)\n",
    "    1. [Handling missing values](#4.1)\n",
    "    1. [Dropping irrelevant features](#4.2)\n",
    "    1. [Dataset separation](#4.3)\n",
    "    1. [Defining set target and features](#4.4)\n",
    "    1. [Scaling: standardization](#4.5)\n",
    "    1. [Encoding categorical features](#4.6)\n",
    "    1. [Preprocessing summary](#4.7)\n",
    "1. [Model training & validation](#5)\n",
    "    1. [Setting the baseline score](#5.1)\n",
    "    1. [With imbalanced data](#5.2)\n",
    "        1. [Decision tree](#5.2.1)\n",
    "        1. [Random forest](#5.2.2)\n",
    "        1. [Logistic regression](#5.2.3)\n",
    "        1. [Conclusion](#5.2.4)\n",
    "    1. [Treating data imbalance](#5.3)\n",
    "        1. [Class weighting](#5.3.1)\n",
    "            1. [Decision tree](#5.3.1.1)\n",
    "            1. [Random forest](#5.3.1.2)\n",
    "            1. [Logistic regression](#5.3.1.3)\n",
    "            1. [Conclusion](#5.3.1.4)\n",
    "        1. [Upsampling](#5.3.2)\n",
    "            1. [Decision tree](#5.3.2.1)\n",
    "            1. [Random forest](#5.3.2.2)\n",
    "            1. [Logistic regression](#5.3.2.3)\n",
    "            1. [Conclusion](#5.3.2.4)\n",
    "    1. [Summary of training and validation results](#5.4)\n",
    "1. [Testing](#6)\n",
    "1. [Conclusion](#7)\n",
    "\n",
    "\n",
    "## Project information <a class=\"anchor\" name=\"1\"></a>\n",
    "\n",
    "Beta Bank is losing customers and the higher-ups came to the conclusion that it would be more profitable to keep loyal customers than attract new ones.\n",
    "\n",
    "We need to create a model capable of correctly predicting whether or not a customer will leave soon. The predictions will serve as a basis for Beta to keep or let go of their clients.\n",
    "\n",
    "Objectives:\n",
    "1. Create an ML model for this task.<br>\n",
    "To ensure that we provided Beta with the best model, we need to do the following steps:</br>\n",
    "1. Train models before and after data preprocessing, and compare the results\n",
    "1. Evaluate the models' performance with several metrics.\n",
    "\n",
    "### Dataset description <a class=\"anchor\" name=\"1.1\"></a>\n",
    "We're provided with a dataset about clients' past behaviors and their history of bank contract termination.\n",
    "\n",
    "Features:\n",
    "\n",
    "- `RowNumber` — index\n",
    "- `CustomerId`\n",
    "- `Surname`\n",
    "- `CreditScore`\n",
    "- `Geography` — country of residence\n",
    "- `Gender`\n",
    "- `Age` — umur\n",
    "- `Tenure` — tenure of customers' fixed deposit (in years)\n",
    "- `Balance` \n",
    "- `NumOfProducts` — number of bank products in use by the customer\n",
    "- `HasCrCard` — whether or not the customer has a credit card\n",
    "- `IsActiveMember` — whether or not the customer is active\n",
    "- `EstimatedSalary`\n",
    "\n",
    "Target:\n",
    "- `Exited` — whether or not the contract has been terminated\n",
    "\n",
    "### Notes <a class=\"anchor\" name=\"1.2\"></a>\n",
    "To ensure that we obtain consistent results, we will use `12345` as our `random_state` hyperparameter throughout the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a30881c",
   "metadata": {},
   "source": [
    "## Loading libraries <a class=\"anchor\" name=\"2\"></a>\n",
    "\n",
    "We'll use classification models (as opposed to regression models) because we need to predict 2 outcomes: whether or not a customer will leave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f24f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataframe manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# ML model libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# sklearn data processing tools\n",
    "## to divide the dataset into subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## to standardize data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## to shuffle data\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "## \n",
    "\n",
    "# sklearn metrics\n",
    "from sklearn.metrics import (f1_score, roc_auc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7023fe2",
   "metadata": {},
   "source": [
    "## Loading dataset <a class=\"anchor\" name=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba5c73d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'datasets/Churn.csv')\n",
    "\n",
    "# Checking the dataset\n",
    "print(df.info())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db8ddc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited == 1: 20.369999999999997 %\n",
      "Exited == 0: 79.63 %\n"
     ]
    }
   ],
   "source": [
    "# Checking target class imbalance\n",
    "print('Exited == 1:', len(df[df['Exited'] == 1])/len(df) * 100, '%')\n",
    "print('Exited == 0:', len(df[df['Exited'] == 0])/len(df) * 100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cb24d0",
   "metadata": {},
   "source": [
    "Findings:\n",
    "- Data types are correct. Features with numerical boolean values will be kept as integers to allow for model calculations.\n",
    "- 9091 customers have missing `tenure` information.\n",
    "- The target class is heavily imbalanced, having nearly 80% of the data with `Exited == 0`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ff4873",
   "metadata": {},
   "source": [
    "## Data preprocessing <a class=\"anchor\" name=\"4\"></a>\n",
    "\n",
    "### Handling missing values <a class=\"anchor\" name=\"4.1\"></a>\n",
    "\n",
    "To prevent from introducing any bias to the data, we will fill the null values in  `tenure` with its median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c74bbc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>15589475</td>\n",
       "      <td>Azikiwe</td>\n",
       "      <td>591</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140469.38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>15766205</td>\n",
       "      <td>Yin</td>\n",
       "      <td>550</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103391.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90878.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>52</td>\n",
       "      <td>15768193</td>\n",
       "      <td>Trevisani</td>\n",
       "      <td>585</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146050.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86424.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>54</td>\n",
       "      <td>15702298</td>\n",
       "      <td>Parkhill</td>\n",
       "      <td>655</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125561.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164040.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>61</td>\n",
       "      <td>15651280</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>742</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136857.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84509.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "30         31    15589475    Azikiwe          591     Spain  Female   39   \n",
       "48         49    15766205        Yin          550   Germany    Male   38   \n",
       "51         52    15768193  Trevisani          585   Germany    Male   36   \n",
       "53         54    15702298   Parkhill          655   Germany    Male   41   \n",
       "60         61    15651280     Hunter          742   Germany    Male   35   \n",
       "\n",
       "    Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "30     NaN       0.00              3          1               0   \n",
       "48     NaN  103391.38              1          0               1   \n",
       "51     NaN  146050.97              2          0               0   \n",
       "53     NaN  125561.97              1          0               0   \n",
       "60     NaN  136857.00              1          0               0   \n",
       "\n",
       "    EstimatedSalary  Exited  \n",
       "30        140469.38       1  \n",
       "48         90878.13       0  \n",
       "51         86424.57       0  \n",
       "53        164040.94       1  \n",
       "60         84509.57       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Tenure'].isnull()].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43d62b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tenure'].fillna(df['Tenure'].median(), inplace=True)\n",
    "df[df['Tenure'].isna()]['Tenure'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a575399",
   "metadata": {},
   "source": [
    "### Dropping irrelevant features <a class=\"anchor\" name=\"4.2\"></a>\n",
    "\n",
    "There is no correlation between customers' leaving and their identification, which means that these features are of no use to our models. We will drop these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54cd7bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42     2.0       0.00              1   \n",
       "1          608     Spain  Female   41     1.0   83807.86              1   \n",
       "2          502    France  Female   42     8.0  159660.80              3   \n",
       "3          699    France  Female   39     1.0       0.00              2   \n",
       "4          850     Spain  Female   43     2.0  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae7921e",
   "metadata": {},
   "source": [
    "### Dataset separation <a class=\"anchor\" name=\"4.3\"></a>\n",
    "\n",
    "Because we were not provided with separate sets for the 3 different stages of model creation, we will divide the available set into 3 with the following proportions: 75% for training, 15% for validation and 10% testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4ef6e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af3803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the dataset into a training set and a second set\n",
    "train_df, df2 = train_test_split(df, train_size=0.75, random_state=12345)\n",
    "\n",
    "# Separating the remaining 25% for validation and testing\n",
    "val_df, test_df = train_test_split(df2, test_size=0.4, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79364d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7500 entries, 226 to 4578\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      7500 non-null   int64  \n",
      " 1   Geography        7500 non-null   object \n",
      " 2   Gender           7500 non-null   object \n",
      " 3   Age              7500 non-null   int64  \n",
      " 4   Tenure           7500 non-null   float64\n",
      " 5   Balance          7500 non-null   float64\n",
      " 6   NumOfProducts    7500 non-null   int64  \n",
      " 7   HasCrCard        7500 non-null   int64  \n",
      " 8   IsActiveMember   7500 non-null   int64  \n",
      " 9   EstimatedSalary  7500 non-null   float64\n",
      " 10  Exited           7500 non-null   int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 703.1+ KB\n",
      "None\n",
      "\n",
      "val_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1500 entries, 946 to 6895\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      1500 non-null   int64  \n",
      " 1   Geography        1500 non-null   object \n",
      " 2   Gender           1500 non-null   object \n",
      " 3   Age              1500 non-null   int64  \n",
      " 4   Tenure           1500 non-null   float64\n",
      " 5   Balance          1500 non-null   float64\n",
      " 6   NumOfProducts    1500 non-null   int64  \n",
      " 7   HasCrCard        1500 non-null   int64  \n",
      " 8   IsActiveMember   1500 non-null   int64  \n",
      " 9   EstimatedSalary  1500 non-null   float64\n",
      " 10  Exited           1500 non-null   int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 140.6+ KB\n",
      "None\n",
      "\n",
      "test_df:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 3237 to 2248\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      1000 non-null   int64  \n",
      " 1   Geography        1000 non-null   object \n",
      " 2   Gender           1000 non-null   object \n",
      " 3   Age              1000 non-null   int64  \n",
      " 4   Tenure           1000 non-null   float64\n",
      " 5   Balance          1000 non-null   float64\n",
      " 6   NumOfProducts    1000 non-null   int64  \n",
      " 7   HasCrCard        1000 non-null   int64  \n",
      " 8   IsActiveMember   1000 non-null   int64  \n",
      " 9   EstimatedSalary  1000 non-null   float64\n",
      " 10  Exited           1000 non-null   int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 93.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Checking each set\n",
    "print('train_df:')\n",
    "print(train_df.info())\n",
    "print()\n",
    "\n",
    "print('val_df:')\n",
    "print(val_df.info())\n",
    "print()\n",
    "\n",
    "print('test_df:')\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e54d75",
   "metadata": {},
   "source": [
    "### Defining set target and features <a class=\"anchor\" name=\"4.4\"></a>\n",
    "\n",
    "In line with our project goals, `Exited` will be our target and the rest will be our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b61e6ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df\n",
    "## Excluding Exited from the set\n",
    "train_features = train_df.drop('Exited', axis=1) \n",
    "train_target = train_df['Exited']\n",
    "\n",
    "# val_df\n",
    "val_features = val_df.drop('Exited', axis=1)\n",
    "val_target = val_df['Exited']\n",
    "\n",
    "# test_df\n",
    "test_features = test_df.drop('Exited', axis=1)\n",
    "test_target = test_df['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bf7ea8",
   "metadata": {},
   "source": [
    "### Scaling: standardization <a class=\"anchor\" name=\"4.5\"></a>\n",
    "\n",
    "The performance of regression models is affected by the difference in data values, especially when features are measured in different units. Simply put, regression models may see data with larger numbers as having more significance than those with smaller values. Scaling increases the efficiency of regression models by converting data values into a uniform scale. To anticipate outliers in the current and future data, we will use standardization, a commonly used scaling method that is more robust to outliers.\n",
    "\n",
    "It should be noted that, due to the difference in algorithms, scaling does not have any effect on tree-based models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be8c439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of StandardScaler\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "# Fitting & transforming training data\n",
    "## Defining a logical slice rule for selecting numerical columns\n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "\n",
    "## .values attribute excludes dataframe headers and prevent errors/warnings\n",
    "train_features[numeric] = standard_scaler.fit_transform(X=train_features[numeric].values)\n",
    "\n",
    "# Transforming validation & test sets\n",
    "val_features[numeric] = standard_scaler.transform(X=val_features[numeric].values)\n",
    "test_features[numeric] = standard_scaler.transform(X=test_features[numeric].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a820b",
   "metadata": {},
   "source": [
    "### Encoding categorical features <a class=\"anchor\" name=\"4.6\"></a>\n",
    "\n",
    "For ML models to determine the correlation between the target and categorical features, these features need to be encoded with numbers. We'll pick one-hot-encoding for this task (as opposed to ordinal encoding, which poses the risk of having the models infer arithmetic correlation between categories). Further, we will drop the first category to prevent redundancy in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0ac9249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.442805</td>\n",
       "      <td>-0.841274</td>\n",
       "      <td>1.446098</td>\n",
       "      <td>-1.224577</td>\n",
       "      <td>0.817772</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.269750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7756</th>\n",
       "      <td>-0.310897</td>\n",
       "      <td>-0.270730</td>\n",
       "      <td>0.719099</td>\n",
       "      <td>0.641783</td>\n",
       "      <td>-0.896874</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960396</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>-0.259274</td>\n",
       "      <td>-0.556002</td>\n",
       "      <td>1.082599</td>\n",
       "      <td>-1.224577</td>\n",
       "      <td>0.817772</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.661864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "226      0.442805 -0.841274  1.446098 -1.224577       0.817772          1   \n",
       "7756    -0.310897 -0.270730  0.719099  0.641783      -0.896874          1   \n",
       "2065    -0.259274 -0.556002  1.082599 -1.224577       0.817772          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
       "226                1        -1.269750                  0                0   \n",
       "7756               1         0.960396                  0                1   \n",
       "2065               0         0.661864                  0                0   \n",
       "\n",
       "      Gender_Male  \n",
       "226             0  \n",
       "7756            0  \n",
       "2065            1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding data\n",
    "train_features = pd.get_dummies(train_features, drop_first=True)\n",
    "val_features = pd.get_dummies(val_features, drop_first=True)\n",
    "test_features = pd.get_dummies(test_features, drop_first=True)\n",
    "train_features.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551106fa",
   "metadata": {},
   "source": [
    "### Preprocessing summary <a class=\"anchor\" name=\"4.7\"></a>\n",
    "\n",
    "So far, we have made these changes to the dataset:\n",
    "1. Filling missing values in `Tenure` with the median,\n",
    "1. Dropping irrelevant features,\n",
    "1. Separating the full dataset into training, validation, and test sets,\n",
    "1. Further separating the sets into feature and target sets,\n",
    "1. Scaled the numerical values with standardization,\n",
    "1. Converted categorical features into numerical boolean format with one-hot encoding.\n",
    "\n",
    "We still haven't addressed one major problem: class imbalance. Handling class imbalance requires more experimentation, so we will do it together with model training to compare the results of different handling methods. That aside, our data is now ready for models to process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62068da2",
   "metadata": {},
   "source": [
    "## Model training & validation <a class=\"anchor\" name=\"5\"></a>\n",
    "\n",
    "we will 3 models with diff hyperparam and diff treatment of class imbalance cimpare results\n",
    "\n",
    "Next, we will train each of the three classification models with varying hyperparameters and evaluate their performance in predicting the validation set. The models' performance will be measured by their validation metric scores (not training scores because they will only rise with more training). That said, the corresponding training score will be displayed for comparison.\n",
    "\n",
    "The precision metric measures correct predictions relative to false positives, while recall does so relative to false negatives. In our case, both false positives and false negatives are equally undesirable and will incur considerable losses for the bank. We need a balance between these two metrics, so we will use a metric that combines both measurements: the F1 score.\n",
    "\n",
    "For overall class prediction capability, we will use the AUC-ROC curve score. Unlike accuracy, AUC-ROC performs well with imbalanced datasets, which is the case in our project.\n",
    "\n",
    "### Setting the baseline score <a class=\"anchor\" name=\"5.1\"></a>\n",
    "\n",
    "The bank instructed us to set the baseline F1 score to `0.59`.\n",
    "\n",
    "\n",
    "### With imbalanced data <a class=\"anchor\" name=\"5.2\"></a>\n",
    "\n",
    "First, we will train our models with the original, imbalanced dataset and see how well they perform.\n",
    "\n",
    "#### Decision tree <a class=\"anchor\" name=\"5.2.1\"></a>\n",
    "\n",
    "The performance of this model varies by tree depth. This means that we have to keep the tree deep enough to produce the best results, but not excessively deep to prevent overfitting and wasting resources. To achieve this, we'll train and validate the model 10 times with increasing depth and pick the one with the best scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25c062c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3384564260197724"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy = df\n",
    "df_dummy['dummy_pred'] = 1\n",
    "dummy_pred = len(df_dummy.query('dummy_pred == 1 & Exited == 1')) / len(df_dummy)\n",
    "dummy_pred_f1_score = (2 * dummy_pred) / (dummy_pred + 1)\n",
    "dummy_pred_f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ec9e920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 5 \n",
      " training F1 score: 0.574170331867253 training AUC-ROC score: 0.8411864651732557 \n",
      " validation F1 score: 0.5686653771760154 validation AUC-ROC score: 0.8347895462709544\n"
     ]
    }
   ],
   "source": [
    "# Defining variables to store scores and models in\n",
    "tree_best_train_f1 = 0\n",
    "tree_best_train_roc_auc = 0\n",
    "tree_best_val_f1 = 0\n",
    "tree_best_val_roc_auc = 0\n",
    "tree_best_depth = 0\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    # Creating & training models with different depths\n",
    "    tree_model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    tree_model.fit(train_features, train_target)\n",
    "    \n",
    "    # Getting training class prediction & correct prediction probability scores\n",
    "    train_pred = tree_model.predict(train_features)\n",
    "    train_f1 = f1_score(train_target, train_pred)\n",
    "    train_proba = tree_model.predict_proba(train_features)[:, 1]\n",
    "    train_roc_auc = roc_auc_score(train_target, train_proba)\n",
    "    \n",
    "    # Validation and obtaining validation class prediction & correct prediction probability scores\n",
    "    val_pred = tree_model.predict(val_features)\n",
    "    val_f1 = f1_score(val_target, val_pred)\n",
    "    val_proba = tree_model.predict_proba(val_features)[:, 1]\n",
    "    val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "    \n",
    "    # Storing the best depth and scores\n",
    "    if (val_f1 > tree_best_val_f1) and (val_roc_auc > tree_best_val_roc_auc):\n",
    "        tree_best_train_f1 = train_f1\n",
    "        tree_best_train_roc_auc = train_roc_auc\n",
    "        tree_best_val_f1 = val_f1 \n",
    "        tree_best_val_roc_auc = val_roc_auc\n",
    "        tree_best_depth = depth\n",
    "    \n",
    "print('Best max_depth:', tree_best_depth, '\\n', \n",
    "      'training F1 score:', tree_best_train_f1, 'training AUC-ROC score:', tree_best_train_roc_auc, '\\n',\n",
    "      'validation F1 score:', tree_best_val_f1, 'validation AUC-ROC score:', tree_best_val_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b60c30",
   "metadata": {},
   "source": [
    "#### Random forest <a class=\"anchor\" name=\"5.2.2\"></a>\n",
    "\n",
    "Next, we'll use the power of more trees (technically, estimators) at once. Being composed of several decision trees, the model's accuracy will vary based on its `max_depth` and the number of its trees (`n_estimators`). `max_depth` will be set from 1--10 and `n_estimators` will range from 10--100 with an increment of 10 estimators in every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36be7a23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training F1 score: 0.6157205240174672 best training AUC-ROC score: 0.9086215600495328 \n",
      " Best validation F1 score: 0.5738396624472574 best validation AUC-ROC score: 0.861529250769757\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=8, n_estimators=40, random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=8, n_estimators=40, random_state=12345)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=8, n_estimators=40, random_state=12345)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining variables to store scores and models in\n",
    "forest_best_train_f1 = 0\n",
    "forest_best_train_roc_auc = 0\n",
    "forest_best_val_f1 = 0\n",
    "forest_best_val_roc_auc = 0\n",
    "forest_best_model = None\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    for estimator in range(10, 101, 10): # Setting the range of estimators with an increase of 10 estimators per iteration\n",
    "        \n",
    "        # Creating & training the model with different max_depth and n_estimators\n",
    "        forest_model = RandomForestClassifier(random_state=12345, max_depth=depth, n_estimators=estimator)\n",
    "        forest_model.fit(train_features, train_target)\n",
    "        \n",
    "        # Getting training class prediction & correct prediction probability scores\n",
    "        train_pred = forest_model.predict(train_features)\n",
    "        train_f1 = f1_score(train_target, train_pred)\n",
    "        train_proba = forest_model.predict_proba(train_features)[:, 1]\n",
    "        train_roc_auc = roc_auc_score(train_target, train_proba)\n",
    "        \n",
    "        # Validation and obtaining validation class prediction & correct prediction probability scores\n",
    "        val_pred = forest_model.predict(val_features)\n",
    "        val_f1 = f1_score(val_target, val_pred)\n",
    "        val_proba = forest_model.predict_proba(val_features)[:, 1]\n",
    "        val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "        \n",
    "        # Storing the best depth and scores\n",
    "        if (val_f1 > forest_best_val_f1) and (val_roc_auc > forest_best_val_roc_auc):\n",
    "            forest_best_train_f1 = train_f1\n",
    "            forest_best_train_roc_auc = train_roc_auc\n",
    "            forest_best_val_f1 = val_f1 \n",
    "            forest_best_val_roc_auc = val_roc_auc\n",
    "            forest_best_model = forest_model\n",
    "            \n",
    "print('Best training F1 score:', forest_best_train_f1, 'best training AUC-ROC score:', forest_best_train_roc_auc, '\\n',\n",
    "      'Best validation F1 score:', forest_best_val_f1, 'best validation AUC-ROC score:', forest_best_val_roc_auc)\n",
    "forest_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cbe3c8",
   "metadata": {},
   "source": [
    "#### Logistic regression <a class=\"anchor\" name=\"5.2.3\"></a>\n",
    "\n",
    "Another way to classify data is to use the logistic regression model. This model is different from the previous two in that it doesn't have a `max_depth` parameter and is affected by scaling done previously. \n",
    "\n",
    "We will compare all five solvers provided by scikit-learn. `sag` and `saga` solvers need a plenty of iterations to fit well, so we will increase the `max_iter` hyperparameter to `3500` for these and use the default value of `100` for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1be34f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liblinear\n",
      "training F1 score: 0.32308443142996585\n",
      "training AUC-ROC score: 0.9558282632160121\n",
      "validation F1 score: 0.30303030303030304\n",
      "validation AUC-ROC score: 0.8641031260691071\n",
      "\n",
      "newton-cg\n",
      "training F1 score: 0.32308443142996585\n",
      "training AUC-ROC score: 0.9558282632160121\n",
      "validation F1 score: 0.2997658079625293\n",
      "validation AUC-ROC score: 0.8641031260691071\n",
      "\n",
      "lbfgs\n",
      "training F1 score: 0.32308443142996585\n",
      "training AUC-ROC score: 0.9558282632160121\n",
      "validation F1 score: 0.2997658079625293\n",
      "validation AUC-ROC score: 0.8641031260691071\n",
      "\n",
      "sag\n",
      "training F1 score: 0.32308443142996585\n",
      "training AUC-ROC score: 0.9558282632160121\n",
      "validation F1 score: 0.2997658079625293\n",
      "validation AUC-ROC score: 0.8641031260691071\n",
      "\n",
      "saga\n",
      "training F1 score: 0.32308443142996585\n",
      "training AUC-ROC score: 0.9558282632160121\n",
      "validation F1 score: 0.2997658079625293\n",
      "validation AUC-ROC score: 0.8641031260691071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "\n",
    "for solver in solver_list:\n",
    "    # Creating & training logistic regression models, \n",
    "    # changing max_iter as needed\n",
    "    if solver == 'sag' or solver == 'saga':\n",
    "        logreg_model = LogisticRegression(random_state=12345, \n",
    "                                          solver=solver, max_iter=3500)\n",
    "    else:\n",
    "        logreg_model = LogisticRegression(random_state=12345, solver=solver)\n",
    "    logreg_model.fit(train_features, train_target)\n",
    "    \n",
    "    # Getting training accuracy scores\n",
    "    train_pred = logreg_model.predict(train_features)\n",
    "    train_f1 = f1_score(train_target, train_pred)\n",
    "    train_proba = forest_model.predict_proba(train_features)[:, 1]\n",
    "    train_roc_auc = roc_auc_score(train_target, train_proba)\n",
    "    print(solver)\n",
    "    print('training F1 score:', train_f1)\n",
    "    print('training AUC-ROC score:', train_roc_auc)\n",
    "\n",
    "    # Validating model & getting accuracy\n",
    "    val_pred = logreg_model.predict(val_features)\n",
    "    val_f1 = f1_score(val_target, val_pred)\n",
    "    val_proba = forest_model.predict_proba(val_features)[:, 1]\n",
    "    val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "    print('validation F1 score:', val_f1)\n",
    "    print('validation AUC-ROC score:', val_roc_auc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5762fca7",
   "metadata": {},
   "source": [
    "#### Conclusion <a class=\"anchor\" name=\"5.2.4\"></a>\n",
    "\n",
    "Feeding the models with the imbalanced data resulted in the following scores:\n",
    "- Decision tree (`max_depth = 6`):\n",
    "    - F1: **~0.569**\n",
    "    - AUC-ROC: **~0.816**\n",
    "- Random forest (`max_depth=9, n_estimators=20`):\n",
    "    - F1: **~0.573**\n",
    "    - AUC-ROC: **~0.861**\n",
    "- Logistic regression (any solver):\n",
    "    - F1: **~0.299**\n",
    "    - AUC-ROC: **~0.864*\n",
    "    \n",
    "None of these models' scores passed our 0.59 threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f6c91e",
   "metadata": {},
   "source": [
    "### Treating data imbalance <a class=\"anchor\" name=\"5.3\"></a>\n",
    "\n",
    "The classes in the full dataset was imbalanced with a 0-to-1 ratio of 4:1. This ratio only changed a little in the training set.\n",
    "\n",
    "Balancing the data greatly reduces the bias introduced by the class proportions, which in turn will increase model performance. We will try several approaches to balance the data.\n",
    "\n",
    "For this section, we will compare the effects of the different approaches on the F1 scores of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "413af28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5998\n",
      "1    1502\n",
      "Name: Exited, dtype: int64\n",
      "0    0.799733\n",
      "1    0.200267\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_target.value_counts(normalize=False))\n",
    "print(train_target.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe86e45e",
   "metadata": {},
   "source": [
    "#### Class weighting <a class=\"anchor\" name=\"5.3.1\"></a>\n",
    "\n",
    "Adjusting class weight means we'll put greater weight on the rarer class: `Exited == 1`. For this approach, we just need to change the `class_weight` hyperparameter to `'balanced'`.\n",
    "\n",
    "##### Decision tree <a class=\"anchor\" name=\"5.3.1.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bfde529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 5 \n",
      " training F1 score: 0.5845272206303724 training AUC-ROC score: 0.8465759114556162 \n",
      " validation F1 score: 0.6024423337856173 validation AUC-ROC score: 0.8448137615463565\n"
     ]
    }
   ],
   "source": [
    "# Defining variables to store scores and models in\n",
    "tree_best_train_f1 = 0\n",
    "tree_best_train_roc_auc = 0\n",
    "tree_best_val_f1 = 0\n",
    "tree_best_val_roc_auc = 0\n",
    "tree_best_depth = 0\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    # Creating & training models with different depths\n",
    "    tree_model = DecisionTreeClassifier(max_depth=depth, random_state=12345, class_weight='balanced')\n",
    "    tree_model.fit(train_features, train_target)\n",
    "    \n",
    "    # Getting training class prediction & correct prediction probability scores\n",
    "    train_pred = tree_model.predict(train_features)\n",
    "    train_f1 = f1_score(train_target, train_pred)\n",
    "    train_proba = tree_model.predict_proba(train_features)[:, 1]\n",
    "    train_roc_auc = roc_auc_score(train_target, train_proba)\n",
    "    \n",
    "    # Validation and obtaining validation class prediction & correct prediction probability scores\n",
    "    val_pred = tree_model.predict(val_features)\n",
    "    val_f1 = f1_score(val_target, val_pred)\n",
    "    val_proba = tree_model.predict_proba(val_features)[:, 1]\n",
    "    val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "    \n",
    "    # Storing the best depth and scores\n",
    "    if (val_f1 > tree_best_val_f1) and (val_roc_auc > tree_best_val_roc_auc):\n",
    "        tree_best_train_f1 = train_f1\n",
    "        tree_best_train_roc_auc = train_roc_auc\n",
    "        tree_best_val_f1 = val_f1 \n",
    "        tree_best_val_roc_auc = val_roc_auc\n",
    "        tree_best_depth = depth\n",
    "    \n",
    "print('Best max_depth:', tree_best_depth, '\\n', \n",
    "      'training F1 score:', tree_best_train_f1, 'training AUC-ROC score:', tree_best_train_roc_auc, '\\n',\n",
    "      'validation F1 score:', tree_best_val_f1, 'validation AUC-ROC score:', tree_best_val_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b542903",
   "metadata": {},
   "source": [
    "##### Random forest  <a class=\"anchor\" name=\"5.3.1.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7726411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training F1 score: 0.7196575970651176 best training AUC-ROC score: 0.9343592782147978 \n",
      " Best validation F1 score: 0.648888888888889 best validation AUC-ROC score: 0.8666689830653438\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=9, n_estimators=20,\n",
       "                       random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=9, n_estimators=20,\n",
       "                       random_state=12345)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_depth=9, n_estimators=20,\n",
       "                       random_state=12345)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining variables to store scores and models in\n",
    "forest_best_train_f1 = 0\n",
    "forest_best_train_roc_auc = 0\n",
    "forest_best_val_f1 = 0\n",
    "forest_best_val_roc_auc = 0\n",
    "forest_best_model = None\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    for estimator in range(10, 101, 10): # Setting the range of estimators with an increase of 10 estimators per iteration\n",
    "        \n",
    "        # Creating & training the model with different max_depth and n_estimators\n",
    "        forest_model = RandomForestClassifier(random_state=12345, max_depth=depth, \n",
    "                                              n_estimators=estimator, class_weight='balanced')\n",
    "        forest_model.fit(train_features, train_target)\n",
    "        \n",
    "        # Getting training class prediction & correct prediction probability scores\n",
    "        train_pred = forest_model.predict(train_features)\n",
    "        train_f1 = f1_score(train_target, train_pred)\n",
    "        train_proba = forest_model.predict_proba(train_features)[:, 1]\n",
    "        train_roc_auc = roc_auc_score(train_target, train_proba)\n",
    "        \n",
    "        # Validation and obtaining validation class prediction & correct prediction probability scores\n",
    "        val_pred = forest_model.predict(val_features)\n",
    "        val_f1 = f1_score(val_target, val_pred)\n",
    "        val_proba = forest_model.predict_proba(val_features)[:, 1]\n",
    "        val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "        \n",
    "        # Storing the best depth and scores\n",
    "        if (val_f1 > forest_best_val_f1) and (val_roc_auc > forest_best_val_roc_auc):\n",
    "            forest_best_train_f1 = train_f1\n",
    "            forest_best_train_roc_auc = train_roc_auc\n",
    "            forest_best_val_f1 = val_f1 \n",
    "            forest_best_val_roc_auc = val_roc_auc\n",
    "            forest_best_model = forest_model\n",
    "            \n",
    "print('Best training F1 score:', forest_best_train_f1, 'best training AUC-ROC score:', forest_best_train_roc_auc, '\\n',\n",
    "      'Best validation F1 score:', forest_best_val_f1, 'best validation AUC-ROC score:', forest_best_val_roc_auc)\n",
    "forest_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b922a",
   "metadata": {},
   "source": [
    "##### Logistic regression <a class=\"anchor\" name=\"5.3.1.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4a48c76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liblinear\n",
      "training F1 score: 0.4883447139157053\n",
      "training AUC-ROC score: 0.9618211618697577\n",
      "validation F1 score: 0.506637168141593\n",
      "validation AUC-ROC score: 0.86308747434143\n",
      "\n",
      "newton-cg\n",
      "training F1 score: 0.4882297551789077\n",
      "training AUC-ROC score: 0.9618211618697577\n",
      "validation F1 score: 0.506637168141593\n",
      "validation AUC-ROC score: 0.86308747434143\n",
      "\n",
      "lbfgs\n",
      "training F1 score: 0.4882297551789077\n",
      "training AUC-ROC score: 0.9618211618697577\n",
      "validation F1 score: 0.506637168141593\n",
      "validation AUC-ROC score: 0.86308747434143\n",
      "\n",
      "sag\n",
      "training F1 score: 0.4882297551789077\n",
      "training AUC-ROC score: 0.9618211618697577\n",
      "validation F1 score: 0.506637168141593\n",
      "validation AUC-ROC score: 0.86308747434143\n",
      "\n",
      "saga\n",
      "training F1 score: 0.4882297551789077\n",
      "training AUC-ROC score: 0.9618211618697577\n",
      "validation F1 score: 0.506637168141593\n",
      "validation AUC-ROC score: 0.86308747434143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "\n",
    "for solver in solver_list:\n",
    "    # Creating & training logistic regression models, \n",
    "    # changing max_iter as needed\n",
    "    if solver == 'sag' or solver == 'saga':\n",
    "        logreg_model = LogisticRegression(random_state=12345, \n",
    "                                          solver=solver, class_weight='balanced', max_iter=3500)\n",
    "    else:\n",
    "        logreg_model = LogisticRegression(random_state=12345, solver=solver, class_weight='balanced')\n",
    "    logreg_model.fit(train_features, train_target)\n",
    "    \n",
    "    # Getting training accuracy scores\n",
    "    train_pred = logreg_model.predict(train_features)\n",
    "    train_f1 = f1_score(train_target, train_pred)\n",
    "    train_proba = forest_model.predict_proba(train_features)[:, 1]\n",
    "    train_roc_auc = roc_auc_score(train_target, train_proba)\n",
    "    print(solver)\n",
    "    print('training F1 score:', train_f1)\n",
    "    print('training AUC-ROC score:', train_roc_auc)\n",
    "\n",
    "    # Validating model & getting accuracy\n",
    "    val_pred = logreg_model.predict(val_features)\n",
    "    val_f1 = f1_score(val_target, val_pred)\n",
    "    val_proba = forest_model.predict_proba(val_features)[:, 1]\n",
    "    val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "    print('validation F1 score:', val_f1)\n",
    "    print('validation AUC-ROC score:', val_roc_auc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4cb1fd",
   "metadata": {},
   "source": [
    "##### Conclusion <a class=\"anchor\" name=\"5.3.1.4\"></a>\n",
    "\n",
    "Adjusting weight yielded the following scores from the models' performance:\n",
    "- Decision tree (`max_depth = 5`):\n",
    "    - F1: **~0.602**\n",
    "    - AUC-ROC: **~0.844**\n",
    "- Random forest (`max_depth=9, n_estimators=20`):\n",
    "    - F1: **~0.648**\n",
    "    - AUC-ROC: **~0.866**\n",
    "- Logistic regression (any solver):\n",
    "    - F1: **~0.506**\n",
    "    - AUC-ROC: **~0.863**\n",
    "    \n",
    "It is evident that all F1 & AUC-ROC scores increased. Our random forest achieved the highest score.\n",
    "\n",
    "\n",
    "#### Upsampling <a class=\"anchor\" name=\"5.3.2\"></a>\n",
    "\n",
    "With upsampling, we will duplicate the observations of the rarer class until both classes have the same amount of observations. `Exited == 0` had about 4 times more data than the other class, so we'll need to duplicate the `Exited == 1` rows 3 times to come close to, but not exceed, the observations of the former class. Then, we have to shuffle the data to prevent learning biases.\n",
    "\n",
    "Scikit-learn doesn't have a built-in function for this method, so we will have to define a function ourselves.\n",
    "\n",
    "Note that a similar method called _downsampling_ exists, in which the more abundant observations are dismissed. We don't want to throw away any existing data, so we will not use this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c85d8abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 observances in original training set: 1502\n",
      "Class 1 observances in upsampled training set: 4506\n"
     ]
    }
   ],
   "source": [
    "def upsample(features, target, upsample_one, repeat, random_state):\n",
    "    \"\"\"\n",
    "    Duplicates the observations of the rarer class\n",
    "    to create an evenly balanced dataset.\n",
    "    \n",
    "    features: an array of features to be upsampled\n",
    "    target: an array of the target/class\n",
    "    upsample_one: if set to True, \n",
    "        upsamples the observations of target/class == 1\n",
    "    repeat: the number of times the rarer class observations\n",
    "        should be repeated\n",
    "    random_state: sets the random state to get consistent results\n",
    "    \"\"\"\n",
    "    # Separating features and targets of each class\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    # Choosing which class observations to upsample\n",
    "    if upsample_one == True:\n",
    "        features_upsampled = pd.concat([features_zeros] + \n",
    "                                       [features_ones] * repeat)\n",
    "        target_upsampled = pd.concat([target_zeros] + \n",
    "                                     [target_ones] * repeat)\n",
    "    else:\n",
    "        features_upsampled = pd.concat([features_ones] + \n",
    "                                       [features_zeros] * repeat)\n",
    "        target_upsampled = pd.concat([target_ones] + \n",
    "                                     [target_zeros] * repeat)\n",
    "    \n",
    "    # Shuffling data\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled,\n",
    "                                                   target_upsampled, \n",
    "                                                   random_state=random_state)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "\n",
    "# Upsampling the training set 4 times\n",
    "features_upsampled, target_upsampled = upsample(train_features,\n",
    "                                                train_target,\n",
    "                                                upsample_one=True,\n",
    "                                                repeat=3,\n",
    "                                                random_state=12345)\n",
    "\n",
    "print(f'Class 1 observances in original training set: {len(train_features[train_target == 1])}',\n",
    "      f'Class 1 observances in upsampled training set: {len(features_upsampled[target_upsampled == 1])}',\n",
    "      sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "046e72c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class count:\n",
      "0    5998\n",
      "1    1502\n",
      "Name: Exited, dtype: int64\n",
      "\n",
      "Upsampled set class count:\n",
      "0    5998\n",
      "1    4506\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Training set class count:', train_target.value_counts(), sep='\\n')\n",
    "print()\n",
    "print('Upsampled set class count:', target_upsampled.value_counts(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d33def",
   "metadata": {},
   "source": [
    "##### Decision tree <a class=\"anchor\" name=\"5.3.2.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59e10034",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 5 \n",
      " training F1 score: 0.7176126389701581 training AUC-ROC score: 0.849859018696423 \n",
      " validation F1 score: 0.6136680613668061 validation AUC-ROC score: 0.8413044175504617\n"
     ]
    }
   ],
   "source": [
    "# Defining variables to store scores and models in\n",
    "tree_best_train_f1 = 0\n",
    "tree_best_train_roc_auc = 0\n",
    "tree_best_val_f1 = 0\n",
    "tree_best_val_roc_auc = 0\n",
    "upsampled_tree_best_depth = 0\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    # Creating & training models with different depths\n",
    "    tree_model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    tree_model.fit(features_upsampled, target_upsampled)\n",
    "    \n",
    "    # Getting training class prediction & correct prediction probability scores\n",
    "    train_pred = tree_model.predict(features_upsampled)\n",
    "    train_f1 = f1_score(target_upsampled, train_pred)\n",
    "    train_proba = tree_model.predict_proba(features_upsampled)[:, 1]\n",
    "    train_roc_auc = roc_auc_score(target_upsampled, train_proba)\n",
    "    \n",
    "    # Validation and obtaining validation class prediction & correct prediction probability scores\n",
    "    val_pred = tree_model.predict(val_features)\n",
    "    val_f1 = f1_score(val_target, val_pred)\n",
    "    val_proba = tree_model.predict_proba(val_features)[:, 1]\n",
    "    val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "    \n",
    "    # Storing the best depth and scores\n",
    "    if (val_f1 > tree_best_val_f1) and (val_roc_auc > tree_best_val_roc_auc):\n",
    "        tree_best_train_f1 = train_f1\n",
    "        tree_best_train_roc_auc = train_roc_auc\n",
    "        tree_best_val_f1 = val_f1 \n",
    "        tree_best_val_roc_auc = val_roc_auc\n",
    "        tree_best_depth = depth\n",
    "    \n",
    "print('Best max_depth:', tree_best_depth, '\\n', \n",
    "      'training F1 score:', tree_best_train_f1, 'training AUC-ROC score:', tree_best_train_roc_auc, '\\n',\n",
    "      'validation F1 score:', tree_best_val_f1, 'validation AUC-ROC score:', tree_best_val_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630561b3",
   "metadata": {},
   "source": [
    "##### Random forest <a class=\"anchor\" name=\"5.3.2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d258fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best training F1 score: 0.7897583844212044 best training AUC-ROC score: 0.9167762978249739 \n",
      " Best validation F1 score: 0.6490683229813665 best validation AUC-ROC score: 0.8648996108450222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=8, random_state=12345)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=8, random_state=12345)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=8, random_state=12345)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining variables to store scores and models in\n",
    "forest_best_train_f1 = 0\n",
    "forest_best_train_roc_auc = 0\n",
    "forest_best_val_f1 = 0\n",
    "forest_best_val_roc_auc = 0\n",
    "forest_best_model = None\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    for estimator in range(10, 101, 10): # Setting the range of estimators with an increase of 10 estimators per iteration\n",
    "        \n",
    "        # Creating & training the model with different max_depth and n_estimators\n",
    "        forest_model = RandomForestClassifier(random_state=12345, max_depth=depth, n_estimators=estimator)\n",
    "        forest_model.fit(features_upsampled, target_upsampled)\n",
    "        \n",
    "        # Getting training class prediction & correct prediction probability scores\n",
    "        train_pred = forest_model.predict(features_upsampled)\n",
    "        train_f1 = f1_score(target_upsampled, train_pred)\n",
    "        train_proba = forest_model.predict_proba(features_upsampled)[:, 1]\n",
    "        train_roc_auc = roc_auc_score(target_upsampled, train_proba)\n",
    "        \n",
    "        # Validation and obtaining validation class prediction & correct prediction probability scores\n",
    "        val_pred = forest_model.predict(val_features)\n",
    "        val_f1 = f1_score(val_target, val_pred)\n",
    "        val_proba = forest_model.predict_proba(val_features)[:, 1]\n",
    "        val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "        \n",
    "        # Storing the best depth and scores\n",
    "        if (val_f1 > forest_best_val_f1) and (val_roc_auc > forest_best_val_roc_auc):\n",
    "            forest_best_train_f1 = train_f1\n",
    "            forest_best_train_roc_auc = train_roc_auc\n",
    "            forest_best_val_f1 = val_f1 \n",
    "            forest_best_val_roc_auc = val_roc_auc\n",
    "            forest_best_model = forest_model\n",
    "            \n",
    "print('Best training F1 score:', forest_best_train_f1, 'best training AUC-ROC score:', forest_best_train_roc_auc, '\\n',\n",
    "      'Best validation F1 score:', forest_best_val_f1, 'best validation AUC-ROC score:', forest_best_val_roc_auc)\n",
    "forest_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3bc8cf",
   "metadata": {},
   "source": [
    "##### Logistic regression <a class=\"anchor\" name=\"5.3.2.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f87f04e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liblinear\n",
      "training F1 score: 0.6329812770043207\n",
      "training AUC-ROC score: 0.9632004498614496\n",
      "validation F1 score: 0.5156250000000001\n",
      "validation AUC-ROC score: 0.8619862940472117\n",
      "\n",
      "newton-cg\n",
      "training F1 score: 0.6329812770043207\n",
      "training AUC-ROC score: 0.9632004498614496\n",
      "validation F1 score: 0.5156250000000001\n",
      "validation AUC-ROC score: 0.8619862940472117\n",
      "\n",
      "lbfgs\n",
      "training F1 score: 0.6329812770043207\n",
      "training AUC-ROC score: 0.9632004498614496\n",
      "validation F1 score: 0.5156250000000001\n",
      "validation AUC-ROC score: 0.8619862940472117\n",
      "\n",
      "sag\n",
      "training F1 score: 0.6329812770043207\n",
      "training AUC-ROC score: 0.9632004498614496\n",
      "validation F1 score: 0.5156250000000001\n",
      "validation AUC-ROC score: 0.8619862940472117\n",
      "\n",
      "saga\n",
      "training F1 score: 0.6329812770043207\n",
      "training AUC-ROC score: 0.9632004498614496\n",
      "validation F1 score: 0.5156250000000001\n",
      "validation AUC-ROC score: 0.8619862940472117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "solver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "\n",
    "for solver in solver_list:\n",
    "    # Creating & training logistic regression models, \n",
    "    # changing max_iter as needed\n",
    "    if solver == 'sag' or solver == 'saga':\n",
    "        logreg_model = LogisticRegression(random_state=12345, solver=solver, max_iter=3500)\n",
    "    else:\n",
    "        logreg_model = LogisticRegression(random_state=12345, solver=solver)\n",
    "    logreg_model.fit(features_upsampled, target_upsampled)\n",
    "    \n",
    "    # Getting training accuracy scores\n",
    "    train_pred = logreg_model.predict(features_upsampled)\n",
    "    train_f1 = f1_score(target_upsampled, train_pred)\n",
    "    train_proba = forest_model.predict_proba(features_upsampled)[:, 1]\n",
    "    train_roc_auc = roc_auc_score(target_upsampled, train_proba)\n",
    "    print(solver)\n",
    "    print('training F1 score:', train_f1)\n",
    "    print('training AUC-ROC score:', train_roc_auc)\n",
    "\n",
    "    # Validating model & getting accuracy\n",
    "    val_pred = logreg_model.predict(val_features)\n",
    "    val_f1 = f1_score(val_target, val_pred)\n",
    "    val_proba = forest_model.predict_proba(val_features)[:, 1]\n",
    "    val_roc_auc = roc_auc_score(val_target, val_proba)\n",
    "    print('validation F1 score:', val_f1)\n",
    "    print('validation AUC-ROC score:', val_roc_auc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2fff18",
   "metadata": {},
   "source": [
    "##### Conclusion <a class=\"anchor\" name=\"5.3.2.4\"></a>\n",
    "\n",
    "Adjusting weight yielded the following scores from the models' performance:\n",
    "- Decision tree (`max_depth = 5`):\n",
    "    - F1: **~0.613**\n",
    "    - AUC-ROC: **~0.841**\n",
    "- Random forest (`max_depth=9, n_estimators=20`):\n",
    "    - F1: **~0.649**\n",
    "    - AUC-ROC: **~0.864**\n",
    "- Logistic regression (any solver):\n",
    "    - F1: **~0.515**\n",
    "    - AUC-ROC: **~0.861**\n",
    "    \n",
    "This time, all F1 scores increased slightly, but AUC-ROC scores suffered some losses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fd19d5",
   "metadata": {},
   "source": [
    "### Summary of training and validation results <a class=\"anchor\" name=\"5.4\"></a>\n",
    "\n",
    "Due to data imbalance, we experimented with three different alternatives:\n",
    "1. trained and validated models with the original, imbalanced dataset as is,\n",
    "1. with weight adjustments,\n",
    "1. with an upsampled dataset.\n",
    "\n",
    "The best models and hyperparameters of each approach were:\n",
    "1. Random forest (`max_depth=9, n_estimators=20`):\n",
    "    - F1: **~0.573**\n",
    "    - AUC-ROC: **~0.861**\n",
    "1. Random forest (`max_depth=9, n_estimators=20`):\n",
    "    - F1: **~0.648**\n",
    "    - AUC-ROC: **~0.866**\n",
    "1. Random forest (`max_depth=9, n_estimators=20`):\n",
    "    - F1: **~0.649**\n",
    "    - AUC-ROC: **~0.864**\n",
    "    \n",
    "The score obtained from the last two methods **passed the 0.59 baseline score**. Weight adjustments made a better AUC-ROC score, but upsampling returned a better F1, with slight score differences each.\n",
    "\n",
    "Between these two choices, we will use the model we trained with **weight adjustments** due to the fact that its F1 score was only 0.001 less, but had a 0.002 higher AUC-ROC score compared to the one trained with an upsampled set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f45900",
   "metadata": {},
   "source": [
    "## Testing <a class=\"anchor\" name=\"6\"></a>\n",
    "\n",
    "Our model needs to go through the final phase: testing. For this stage, we will recreate the aforementioned model with the same hyperparameters, train it using the combined training and validation set, then test its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5578df91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score: 0.6296296296296295\n",
      "Test AUC-ROC score: 0.8562900858868444\n"
     ]
    }
   ],
   "source": [
    "# Combining training and validation sets\n",
    "final_features = pd.concat([train_features] + [val_features])\n",
    "final_target = pd.concat([train_target] + [val_target])\n",
    "\n",
    "# Creating and training model\n",
    "final_model = RandomForestClassifier(max_depth=9, n_estimators=20, class_weight='balanced', random_state=12345)\n",
    "final_model.fit(final_features, final_target)\n",
    "\n",
    "# Testing\n",
    "test_pred = final_model.predict(test_features)\n",
    "test_f1 = f1_score(test_target, test_pred)\n",
    "\n",
    "test_proba = final_model.predict_proba(test_features)[:, 1]\n",
    "test_roc_auc = roc_auc_score(test_target, test_proba)\n",
    "\n",
    "print('Test F1 score:', test_f1)\n",
    "print('Test AUC-ROC score:', test_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d150d",
   "metadata": {},
   "source": [
    "Despite the slight score decrease, our model succeeded the test, surpassing the baseline score with an F1 of **0.629** and AUC-ROC score of **0.856**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f0149",
   "metadata": {},
   "source": [
    "## Conclusion <a class=\"anchor\" name=\"7\"></a>\n",
    "\n",
    "We were given a dataset of 10000 observations.\n",
    "\n",
    "In preprocessing, we made the following changes to the set:\n",
    "1. Filling missing values in `Tenure` with the median,\n",
    "1. Dropping irrelevant features,\n",
    "1. Separating the full dataset into training, validation, and test sets,\n",
    "1. Further separating the sets into feature and target sets,\n",
    "1. Scaled the numerical values with standardization,\n",
    "1. Converted categorical features into numerical boolean format with one-hot encoding.\n",
    "\n",
    "The data was heavily imbalanced, having 4 times more observations of target class `Exited == 0`. We tried training models with different approaches to this problem, and concluded that the best solution was to balance the training set with class weight adjustments.\n",
    "\n",
    "The final model will be a **random forest classifier** trained with this dataset, with the following hyperparameters:\n",
    "- `max_depth = 9`\n",
    "- `n_estimators = 20`\n",
    "- `class_weight = 'balanced'`\n",
    "- `random_state = 12345`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
